{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: model.tflite/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-30b92979558c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model = keras.models.load_model('model_4.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: model.tflite/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('model_4.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtzan_music_speech\n",
      "librispeech\n",
      "librispeech_lm\n",
      "ljspeech\n",
      "speech_commands\n",
      "tfds.core.DatasetInfo(\n",
      "    name='speech_commands',\n",
      "    version=0.0.2,\n",
      "    description='An audio dataset of spoken words designed to help train and evaluate keyword\n",
      "spotting systems. Its primary goal is to provide a way to build and test small\n",
      "models that detect when a single word is spoken, from a set of ten target words,\n",
      "with as few false positives as possible from background noise or unrelated\n",
      "speech. Note that in the train and validation set, the label \"unknown\" is much\n",
      "more prevalent than the labels of the target words or background noise.\n",
      "One difference from the release version is the handling of silent segments.\n",
      "While in the test set the silence segments are regular 1 second files, in the\n",
      "training they are provided as long segments under \"background_noise\" folder.\n",
      "Here we split these background noise into 1 second clips, and also keep one of\n",
      "the files for the validation set.',\n",
      "    homepage='https://arxiv.org/abs/1804.03209',\n",
      "    features=FeaturesDict({\n",
      "        'audio': Audio(shape=(None,), dtype=tf.int64),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=12),\n",
      "    }),\n",
      "    total_num_examples=100503,\n",
      "    splits={\n",
      "        'test': 4890,\n",
      "        'train': 85511,\n",
      "        'validation': 10102,\n",
      "    },\n",
      "    supervised_keys=('audio', 'label'),\n",
      "    citation=\"\"\"@article{speechcommandsv2,\n",
      "       author = {{Warden}, P.},\n",
      "        title = \"{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}\",\n",
      "      journal = {ArXiv e-prints},\n",
      "      archivePrefix = \"arXiv\",\n",
      "      eprint = {1804.03209},\n",
      "      primaryClass = \"cs.CL\",\n",
      "      keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},\n",
      "        year = 2018,\n",
      "        month = apr,\n",
      "        url = {https://arxiv.org/abs/1804.03209},\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.lite as lite\n",
    "import tensorflow_datasets as tfds\n",
    "dataset_name = \"speech_commands\"\n",
    "\n",
    "\n",
    "speech_builder = tfds.builder(dataset_name)\n",
    "for ele in tfds.list_builders():\n",
    "    if \"speech\" in ele:\n",
    "        print(ele)\n",
    "\n",
    "dataset_name = \"speech_commands\"\n",
    "\n",
    "# instantiate a dataset builder (see tensorflow dataset builder)\n",
    "speech_builder = tfds.builder(dataset_name)\n",
    "print(speech_builder.info)\n",
    "\n",
    "# download data into existing data folder\n",
    "speech_builder.download_and_prepare()\n",
    "data = speech_builder.as_dataset(as_supervised=True)\n",
    "test_set = data['test']\n",
    "test_set_size = 4890\n",
    "\n",
    "\n",
    "def make_mfccs(audio, labels):\n",
    "    \n",
    "    FRAME_RATE = 16000\n",
    "    \n",
    "    stfts = tf.signal.stft(tf.cast(audio, tf.float32), frame_length=1024, frame_step=256,\n",
    "                       fft_length=1024)\n",
    "    \n",
    "    spectrograms = tf.abs(stfts)\n",
    "\n",
    "    # Warp the linear scale spectrograms into the mel-scale.\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(num_mel_bins, num_spectrogram_bins,\n",
    "                                                                        FRAME_RATE, lower_edge_hertz,\n",
    "                                                                        upper_edge_hertz)\n",
    "    \n",
    "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    \n",
    "    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
    "\n",
    "    # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "\n",
    "    # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "    # You can use other parts, or even all of the MFCCs, to test around how it affect the accuracy\n",
    "    mfcc = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :13]\n",
    "    \n",
    "    # Finally add depth to the mfcc tensors, our Conv2D-Model requires this.\n",
    "    mfcc = tf.expand_dims(mfcc, -1)\n",
    "    \n",
    "    return mfcc, labels\n",
    "\n",
    "dataset_test = test_set.map(make_mfccs\n",
    "                           ).padded_batch(128\n",
    "                           ).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(predictions, dataset):\n",
    "    total, correct = 0, 0\n",
    "    index = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        for b_ele in batch[1]:\n",
    "            #print(b_ele)\n",
    "            total += 1\n",
    "            if b_ele == np.argmax(predictions[index]):\n",
    "                correct += 1\n",
    "            index += 1\n",
    "\n",
    "\n",
    "    print(\"{} out of {} correct, resulting in an accuracy of {}\\n\".format(correct, total, (correct/total)*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 21s 547ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(dataset_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4242 out of 4890 correct, resulting in an accuracy of 86.74846625766871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calc_acc(preds, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4242 out of 4890 correct, resulting in an accuracy of 86.74846625766871\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total, correct = 0, 0\n",
    "index = 0\n",
    "\n",
    "for batch in dataset_test:\n",
    "    for b_ele in batch[1]:\n",
    "        #print(b_ele)\n",
    "        total += 1\n",
    "        if b_ele == np.argmax(preds[index]):\n",
    "            correct += 1\n",
    "        index += 1\n",
    "        \n",
    "        \n",
    "print(\"{} out of {} correct, resulting in an accuracy of {}\".format(correct, total, (correct/total)*100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = data['validation']\n",
    "validation_set_size = 10102\n",
    "dataset_validation = validation_set.map(make_mfccs\n",
    "                                       ).padded_batch(128\n",
    "                                       ).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 76s 968ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(dataset_validation, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9493 out of 10102 correct, resulting in an accuracy of 93.9714907939022\n"
     ]
    }
   ],
   "source": [
    "total, correct = 0, 0\n",
    "index = 0\n",
    "\n",
    "for batch in dataset_validation:\n",
    "    for b_ele in batch[1]:\n",
    "        #print(b_ele)\n",
    "        total += 1\n",
    "        if b_ele == np.argmax(preds[index]):\n",
    "            correct += 1\n",
    "        index += 1\n",
    "        \n",
    "        \n",
    "print(\"{} out of {} correct, resulting in an accuracy of {}\".format(correct, total, (correct/total)*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert batched tfds into numpy for tflite inference\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.zeros((test_set_size, 59,13,1))\n",
    "label_arr = np.zeros((test_set_size,1))\n",
    "#print(data.shape)\n",
    "\n",
    "index = 0\n",
    "for batch in dataset_test:\n",
    "    audio = batch[0]\n",
    "    labels = batch[1]\n",
    "    for audio, label in zip(audio, labels):\n",
    "        \n",
    "        #print(ele)\n",
    "        #print(audio.shape)\n",
    "        #print(label.numpy())\n",
    "        data[index] = audio.numpy()\n",
    "        label_arr[index] = label.numpy()\n",
    "        #print(label_arr[index])\n",
    "        \n",
    "        index += 1\n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float32  shape:  (59, 13, 1)\n",
      "#######################\n",
      "[7.]\n",
      "#######################\n",
      "[2.]\n",
      "#######################\n",
      "[6.]\n",
      "#######################\n",
      "[8.]\n",
      "#######################\n",
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "test_arr = data[1]\n",
    "test_arr = test_arr.astype('float32')\n",
    "#test_arr = np.expand_dims(test_arr, 0)\n",
    "print(type(test_arr), test_arr.dtype, \" shape: \", test_arr.shape)\n",
    "\n",
    "for i in range(5):\n",
    "    #print(data[i])\n",
    "    print(\"#######################\")\n",
    "    print(label_arr[i])\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details:\t\t\t\tOutput Details:\n",
      "name: conv2d_input\t\t | \t\tname: Identity\n",
      "index: 20\t\t | \t\tindex: 21\n",
      "shape: [ 1 59 13  1]\t\t | \t\tshape: [ 1 12]\n",
      "shape_signature: [-1 59 13  1]\t\t | \t\tshape_signature: [-1 12]\n",
      "dtype: <class 'numpy.uint8'>\t\t | \t\tdtype: <class 'numpy.uint8'>\n",
      "quantization: (1.3954178094863892, 125)\t\t | \t\tquantization: (0.00390625, 0)\n",
      "quantization_parameters: {'scales': array([1.3954178], dtype=float32), 'zero_points': array([125], dtype=int32), 'quantized_dimension': 0}\t\t | \t\tquantization_parameters: {'scales': array([0.00390625], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}\n",
      "sparsity_parameters: {}\t\t | \t\tsparsity_parameters: {}\n",
      "################################\n",
      "[ 1 59 13  1]\n",
      "uint8 (1, 59, 13, 1)\n",
      "[[  0   0 255   0   0   0   0   0   0   0   0   0]] (1, 12)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load the model and make some quick tests\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "full_int_quanti = True\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "\n",
    "if full_int_quanti:\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"model_only_ints.tflite\")\n",
    "else:\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input Details:\\t\\t\\t\\tOutput Details:\")\n",
    "for in_items, out_items in zip(input_details[0].items(), output_details[0].items()):\n",
    "    print(\"{}: {}\\t\\t | \\t\\t{}: {}\".format(in_items[0],in_items[1],out_items[0],out_items[1]))\n",
    "print(\"################################\")\n",
    "# Test the model on random input data.\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "\n",
    "if full_int_quanti:\n",
    "    input_data = test_arr.astype('uint8')\n",
    "    input_data = np.expand_dims(input_data, 0)\n",
    "else:\n",
    "    input_data = test_arr\n",
    "\n",
    "print(input_data.dtype, input_data.shape)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data, output_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe it always predicts the last label (unknown) because it's so overrepresented in the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"inference loop for lite model\"\"\"\n",
    "preds = np.zeros((test_set_size, 12)) # dataset size and number of labels\n",
    "\n",
    "for i, input_data in enumerate(data):\n",
    "    # Some data adjustment\n",
    "    \n",
    "    #input_data = input_data.astype('float32')\n",
    "    input_data = input_data.astype('uint8')\n",
    "    #print(input_data.shape)\n",
    "    input_data = np.expand_dims(input_data, 0)\n",
    "    \n",
    "    #print(input_data.shape)\n",
    "    #break\n",
    "    \n",
    "    # Inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    preds[i] = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    #print(output_data.shape, preds.shape)\n",
    "    \n",
    "    #preds[i] = output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0. 255.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "4885\n",
      "445 out of 4890 correct, resulting in an accuracy of 9.100204498977506\n",
      "2 4559\n",
      "1 146\n",
      "8 43\n",
      "11 104\n",
      "3 19\n",
      "7 12\n",
      "9 2\n",
      "0 5\n"
     ]
    }
   ],
   "source": [
    "total, correct = 0, 0\n",
    "index = 0\n",
    "print(preds[6])\n",
    "not_null = 0\n",
    "predicted_label_count = {}\n",
    "\n",
    "for i, label in enumerate(label_arr):\n",
    "    prediction = np.argmax(preds[i])\n",
    "    if prediction in predicted_label_count:\n",
    "        predicted_label_count[prediction] += 1\n",
    "    else:\n",
    "        predicted_label_count[prediction] = 1\n",
    "        \n",
    "    if prediction == label:\n",
    "        \n",
    "        correct += 1\n",
    "    total += 1\n",
    "    if prediction != 0:\n",
    "        not_null += 1\n",
    "        \n",
    "print(not_null)\n",
    "print(\"{} out of {} correct, resulting in an accuracy of {}\".format(correct, total, (correct/total)*100))\n",
    "for key, val in predicted_label_count.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4890, 12)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)\n",
    "for i in range(10):\n",
    "    print(preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keywords2",
   "language": "python",
   "name": "keywords2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
