{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# virtualenv check\n",
    "import sys\n",
    "\n",
    "def get_base_prefix_compat():\n",
    "    \"\"\"Get base/real prefix, or sys.prefix if there is none.\"\"\"\n",
    "    return getattr(sys, \"base_prefix\", None) or getattr(sys, \"real_prefix\", None) or sys.prefix\n",
    "\n",
    "def in_virtualenv():\n",
    "    return get_base_prefix_compat() != sys.prefix\n",
    "\n",
    "print(in_virtualenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greetings!\n",
    "\n",
    "## Simple Keyword Recognition on a google coral TPU\n",
    "\n",
    "This notebook is a little showcase and tutorial on how to train a simple speech-recognition model through deep learning. To keep training times low and model size small, we'll focus on keywords (a wakeword an some commands like \"on\", \"off\", etc.) \n",
    "\n",
    "Because we want to deploy our model on google's tpu, we'll use tensorflow and tensorflow lite. This will also make the model creation, paramter searching and training a breeze. On top of that, tensorflow has strong deployment options.\n",
    "\n",
    "This notebook concerns only the neural network. Another one will cover model deployment in an end-to-end system on a raspberry pi with connected tpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.lite as lite\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_data_validation\n",
    "import pydub\n",
    "import librosa\n",
    "#import kapre\n",
    "#import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Datasets\n",
    "\n",
    "Tensorflow datasets (tfds) are a quick way of acquiring data. The dataset object comes with a multitude of methods to transform the data and serve it to the model. It also conviently displays info about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"speech_commands\"\n",
    "\n",
    "\n",
    "speech_builder = tfds.builder(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtzan_music_speech\n",
      "librispeech\n",
      "librispeech_lm\n",
      "ljspeech\n",
      "speech_commands\n",
      "tfds.core.DatasetInfo(\n",
      "    name='speech_commands',\n",
      "    version=0.0.2,\n",
      "    description='An audio dataset of spoken words designed to help train and evaluate keyword\n",
      "spotting systems. Its primary goal is to provide a way to build and test small\n",
      "models that detect when a single word is spoken, from a set of ten target words,\n",
      "with as few false positives as possible from background noise or unrelated\n",
      "speech. Note that in the train and validation set, the label \"unknown\" is much\n",
      "more prevalent than the labels of the target words or background noise.\n",
      "One difference from the release version is the handling of silent segments.\n",
      "While in the test set the silence segments are regular 1 second files, in the\n",
      "training they are provided as long segments under \"background_noise\" folder.\n",
      "Here we split these background noise into 1 second clips, and also keep one of\n",
      "the files for the validation set.',\n",
      "    homepage='https://arxiv.org/abs/1804.03209',\n",
      "    features=FeaturesDict({\n",
      "        'audio': Audio(shape=(None,), dtype=tf.int64),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=12),\n",
      "    }),\n",
      "    total_num_examples=100503,\n",
      "    splits={\n",
      "        'test': 4890,\n",
      "        'train': 85511,\n",
      "        'validation': 10102,\n",
      "    },\n",
      "    supervised_keys=('audio', 'label'),\n",
      "    citation=\"\"\"@article{speechcommandsv2,\n",
      "       author = {{Warden}, P.},\n",
      "        title = \"{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}\",\n",
      "      journal = {ArXiv e-prints},\n",
      "      archivePrefix = \"arXiv\",\n",
      "      eprint = {1804.03209},\n",
      "      primaryClass = \"cs.CL\",\n",
      "      keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},\n",
      "        year = 2018,\n",
      "        month = apr,\n",
      "        url = {https://arxiv.org/abs/1804.03209},\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"!!! DOWNLOAD WARNING !!!\n",
    "\n",
    "This cells downloads the speech commands dataset. Will not download twice, if it detects an already\n",
    "downloaded version.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# looking for speech commands dataset in all available datasets...\n",
    "for ele in tfds.list_builders():\n",
    "    if \"speech\" in ele:\n",
    "        print(ele)\n",
    "\n",
    "dataset_name = \"speech_commands\"\n",
    "\n",
    "# instantiate a dataset builder (see tensorflow dataset builder)\n",
    "speech_builder = tfds.builder(dataset_name)\n",
    "print(speech_builder.info)\n",
    "\n",
    "# download data into existing data folder\n",
    "speech_builder.download_and_prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down', 'go', 'left', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes', '_silence_', '_unknown_']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get some info from the builder about the dataset\"\"\"\n",
    "builder_info = speech_builder.info\n",
    "num_labels = builder_info.features['label'].num_classes\n",
    "label_list = builder_info.features['label'].names\n",
    "\n",
    "\"\"\"Not we actually acquire the dataset object. As supervised gives us a dataset of tuples: data and label\"\"\"\n",
    "data = speech_builder.as_dataset(as_supervised=True)\n",
    "\n",
    "assert isinstance(data, dict)\n",
    "\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = data['test']\n",
    "train_set = data['train']\n",
    "validation_set = data['validation']\n",
    "\n",
    "test_set_size = 4890\n",
    "train_set_size = 85511\n",
    "validation_set_size = 10102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n",
      "The dataset consists of:  <class 'tuple'>\n",
      "How does a label object look like:  tf.Tensor(7, shape=(), dtype=int64)\n",
      "How does a audio object look like:  tf.Tensor([  -1   -2   -2 ... -136 -170 -203], shape=(16000,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(type(test_set))\n",
    "for thing in test_set:\n",
    "    print(\"The dataset consists of: \", type(thing))\n",
    "    \n",
    "    print(\"How does a label object look like: \", thing[1])\n",
    "    print(\"How does a audio object look like: \", thing[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Before fitting any model, we need to look at our data and preprocess it, in order to make it actually usuable.\n",
    "\n",
    "### Data\n",
    "While for visual data this often means slightly transforming the images to get more variability, working with audio requires an additional step: feature extraction. There are attempts to use raw audio data in deep neural networks, but current state of the art systems for speech recognition often use specialized features that can be computed from the raw audio signal: mel frequency cepstral coefficents. \n",
    "\n",
    "There are audio libaries like librosa that make the extraction rather easy, but because we're working with tensorflow Datasets it's best to stay in its context. We find an example how to extract mfcc working with tensorflow tools in the official documentation. We pack it into a function for later use.\n",
    "\n",
    "\n",
    "### Labels\n",
    "Converting to one hot encodings is only needed when we dont want to use sparse categorical entropy loss,\n",
    "We further need to convert the labels which are currently simply integers to a one-hot representation. Again, tensorflow already offers a neat function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mfccs(audio, labels):\n",
    "    \n",
    "    frame_rate=16000\n",
    "    stfts = tf.signal.stft(tf.cast(audio, tf.float32), frame_length=1024, frame_step=256,\n",
    "                       fft_length=1024)\n",
    "    #print(type(stfts))\n",
    "    spectrograms = tf.abs(stfts)\n",
    "\n",
    "    # Warp the linear scale spectrograms into the mel-scale.\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(num_mel_bins, num_spectrogram_bins,\n",
    "                                                                        sample_rate, lower_edge_hertz,\n",
    "                                                                        upper_edge_hertz)\n",
    "    \n",
    "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    \n",
    "    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
    "\n",
    "    # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "\n",
    "    # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "    mfcc = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :13]\n",
    "    #print(mfcc.shape)\n",
    "    # Finally add depth to the mfcc tensors, our Conv2D-Model requires this.\n",
    "    print(mfcc.shape)\n",
    "    mfcc = tf.expand_dims(mfcc, -1)\n",
    "    print(mfcc.shape)\n",
    "    print(labels)\n",
    "    #labels = tf.keras.utils.to_categorical(labels, num_classes=num_labels)\n",
    "    return mfcc, labels\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 13)\n",
      "(None, None, 13, 1)\n",
      "Tensor(\"args_1:0\", shape=(None,), dtype=int64)\n",
      "(None, None, 13)\n",
      "(None, None, 13, 1)\n",
      "Tensor(\"args_1:0\", shape=(None,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "#ToDo: make them the same length!\n",
    "dataset_1 = test_set.batch(256\n",
    "                          ).map(make_mfccs\n",
    "                          #).map(lambda audio, label: (tf.expand_dims(audio, -1),label)\n",
    "                          #).cache('mfcc_data'\n",
    "                          ).shuffle(test_set_size, reshuffle_each_iteration=True\n",
    "                          ).repeat(EPOCHS)\n",
    "\n",
    "dataset_validation = validation_set.batch(256\n",
    "                          ).map(make_mfccs\n",
    "                          #).map(lambda audio, label: (tf.expand_dims(audio, -1),label)\n",
    "                          #).cache('mfcc_data'\n",
    "                          ).shuffle(validation_set_size, reshuffle_each_iteration=True\n",
    "                          ).repeat(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 59, 13, 1)\n",
      "tf.Tensor(\n",
      "[ 5  9  3  2  8  1  3  2  5  8  2  2  3 11  0  6  8  0 11  3  8  8 11 10\n",
      "  9  5], shape=(26,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for thing in dataset_1:\n",
    "    audio = thing[0]\n",
    "    label = thing[1]\n",
    "    print(audio.shape)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHY THE FUCK IS THE ABOVE LABEL SHAPE 26 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Build\n",
    "\n",
    "Next, we build a standard Convolutional Neural Network with a little twist. Instead of doing feature extraction beforehand, in a preprocessing-pipeline, we'll use the specialized layers provided by kapre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_82 (Conv2D)           (None, 57, 11, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 55, 9, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 55, 9, 128)        512       \n",
      "_________________________________________________________________\n",
      "re_lu_38 (ReLU)              (None, 55, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 27, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 26, 3, 64)         32832     \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 25, 2, 64)         16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 25, 2, 64)         256       \n",
      "_________________________________________________________________\n",
      "re_lu_39 (ReLU)              (None, 25, 2, 64)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                780       \n",
      "_________________________________________________________________\n",
      "softmax_13 (Softmax)         (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 199,692\n",
      "Trainable params: 199,308\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"!!!Custom layers cant be saved and loaded easily, switch to a standard model and make preprocessing beforehand\"\"\"\n",
    "\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, GlobalAveragePooling2D, Dense, Softmax\n",
    "from kapre.composed import get_melspectrogram_layer, get_log_frequency_spectrogram_layer\n",
    "\n",
    "input_shape = (59,13,1)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\"\"\"\n",
    "melgram_layer = get_melspectrogram_layer(input_shape=input_shape, n_fft=2048,# win_length=2018, hop_length=1024,\n",
    "                                         return_decibel=True, #n_mels=40,\n",
    "                                        input_data_format='channels_last', output_data_format='channels_last',\n",
    "                                        sample_rate=16000, name='melspectro_layer')\n",
    "model.add(melgram_layer)\n",
    "model.add(kapre.LogmelToMFCC(n_mfccs=80))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Conv2D(128, (3), strides=1, input_shape=input_shape))\n",
    "model.add(Conv2D(128, (3), strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size=2, padding=\"valid\"))\n",
    "\n",
    "model.add(Conv2D(64, 2, strides=1))\n",
    "model.add(Conv2D(64, 2, strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "\n",
    "#model.add(Conv2D(6, (2, 2), strides=(2, 2)))\n",
    "#model.add(Conv2D(16, (2, 2), strides=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(ReLU())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "#model.add(Dense(1))\n",
    "model.add(Softmax())\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', 'sparse_categorical_crossentropy')#, run_eagerly=False)#'categorical_crossentropy', 'mse'\n",
    "model.build()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.7215"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Cannot batch tensors with different shapes in component 0. First element had shape [16000] and element 1 had shape [15018].\n\t [[node IteratorGetNext (defined at <ipython-input-274-b7d19e468d33>:1) ]] [Op:__inference_test_function_27305]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-b7d19e468d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Cannot batch tensors with different shapes in component 0. First element had shape [16000] and element 1 had shape [15018].\n\t [[node IteratorGetNext (defined at <ipython-input-274-b7d19e468d33>:1) ]] [Op:__inference_test_function_27305]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataset_1, validation_data=dataset_validation, epochs=40, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data[\"train\"]\n",
    "train_dataset = tfds.as_numpy(train_dataset) \n",
    "#print(train_dataset)\n",
    "x_train = np.zeros((85511, 16000))\n",
    "y_train = np.empty((85511))\n",
    "\n",
    "for i, dic in enumerate(train_dataset):\n",
    "    \n",
    "    # seperate the x and y\n",
    "    x = dic[\"audio\"]\n",
    "    x_train[i][:x.shape[0]] = x\n",
    "    y_train[i] = dic[\"label\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4889"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 0\n",
    "for i,x in enumerate(tfds.as_numpy(data['test'])):\n",
    "    \n",
    "    y = i\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9778\n",
      "Epoch 00001: val_loss improved from inf to 1.45230, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 429s 6s/step - loss: 1.9778 - val_loss: 1.4523\n",
      "Epoch 2/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5295\n",
      "Epoch 00002: val_loss improved from 1.45230 to 1.34877, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 426s 6s/step - loss: 1.5295 - val_loss: 1.3488\n",
      "Epoch 3/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3254\n",
      "Epoch 00003: val_loss improved from 1.34877 to 1.29695, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 428s 6s/step - loss: 1.3254 - val_loss: 1.2969\n",
      "Epoch 4/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2026\n",
      "Epoch 00004: val_loss improved from 1.29695 to 1.19546, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 434s 6s/step - loss: 1.2026 - val_loss: 1.1955\n",
      "Epoch 5/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0990\n",
      "Epoch 00005: val_loss improved from 1.19546 to 1.14167, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 409s 6s/step - loss: 1.0990 - val_loss: 1.1417\n",
      "Epoch 6/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9989\n",
      "Epoch 00006: val_loss improved from 1.14167 to 1.07601, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 418s 6s/step - loss: 0.9989 - val_loss: 1.0760\n",
      "Epoch 7/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9040\n",
      "Epoch 00007: val_loss improved from 1.07601 to 0.94476, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 413s 6s/step - loss: 0.9040 - val_loss: 0.9448\n",
      "Epoch 8/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8186\n",
      "Epoch 00008: val_loss did not improve from 0.94476\n",
      "67/67 [==============================] - 413s 6s/step - loss: 0.8186 - val_loss: 1.0767\n",
      "Epoch 9/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7280\n",
      "Epoch 00009: val_loss improved from 0.94476 to 0.82710, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 407s 6s/step - loss: 0.7280 - val_loss: 0.8271\n",
      "Epoch 10/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6519\n",
      "Epoch 00010: val_loss improved from 0.82710 to 0.82031, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 408s 6s/step - loss: 0.6519 - val_loss: 0.8203\n",
      "Epoch 11/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5835\n",
      "Epoch 00011: val_loss improved from 0.82031 to 0.70563, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 417s 6s/step - loss: 0.5835 - val_loss: 0.7056\n",
      "Epoch 12/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5179\n",
      "Epoch 00012: val_loss improved from 0.70563 to 0.70541, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 419s 6s/step - loss: 0.5179 - val_loss: 0.7054\n",
      "Epoch 13/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4624\n",
      "Epoch 00013: val_loss improved from 0.70541 to 0.56974, saving model to model_3.hdf5\n",
      "67/67 [==============================] - 421s 6s/step - loss: 0.4624 - val_loss: 0.5697\n",
      "Epoch 14/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4182\n",
      "Epoch 00014: val_loss did not improve from 0.56974\n",
      "67/67 [==============================] - 418s 6s/step - loss: 0.4182 - val_loss: 0.6984\n",
      "Epoch 15/40\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3728"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-96f6c9ec4df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             ]\n\u001b[1;32m     15\u001b[0m model.fit(x_train, y_train_trans, validation_split=0.8, shuffle=True,  batch_size=256, epochs=40, verbose=1,\n\u001b[0;32m---> 16\u001b[0;31m          callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.pyenv/versions/keywords2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model_nr = str(3)\n",
    "\"\"\"\n",
    "# 1: 40 mfcc acc: 63\n",
    "# 2: 80 mfcc acc: \n",
    "# 3: 80 mfcc, + maxpooling after first conv, acc: 43\n",
    "\"\"\"\n",
    "model_path = \"model_\"+model_nr+\".hdf5\"\n",
    "\n",
    "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode=\"auto\", restore_best_weights=True),\n",
    "            ModelCheckpoint(model_path, monitor=\"val_loss\", verbose=1, save_best_only=True,\n",
    "                            save_weights_only=False, mode=\"min\",save_freq=\"epoch\",options=None)\n",
    "            ]\n",
    "model.fit(x_train, y_train_trans, validation_split=0.8, shuffle=True,  batch_size=256, epochs=40, verbose=1,\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = data[\"test\"]\n",
    "test_dataset = tfds.as_numpy(test_dataset) \n",
    "#print(train_dataset)\n",
    "x_test = np.zeros((4890, 16000))\n",
    "y_test = np.empty((4890))\n",
    "\n",
    "for i, dic in enumerate(test_dataset):\n",
    "    \n",
    "    # seperate the x and y\n",
    "    x = dic[\"audio\"]\n",
    "    x_test[i][:x.shape[0]] = x\n",
    "    y_test[i] = dic[\"label\"]\n",
    "    \n",
    "y_test_trans = tf.keras.utils.to_categorical(y_test, num_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 23s 149ms/step\n"
     ]
    }
   ],
   "source": [
    "#ToDo: Test if the whole dataset can be input to predict, like the docs say\n",
    "\n",
    "preds = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2143 out of 4890 correct, resulting in an accuracy of 43.8241308793456\n"
     ]
    }
   ],
   "source": [
    "#Todo: Plot!\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "#results = #make hier argmax\n",
    "for pred_idx, target in zip(preds, y_test_trans):\n",
    "    total += 1\n",
    "    if target[np.argmax(pred_idx)]==1:\n",
    "        correct += 1\n",
    "    \n",
    "\n",
    "print(\"{} out of {} correct, resulting in an accuracy of {}\".format(correct, total, (correct/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406 out of 4890 correct, resulting in an accuracy of 8.302658486707566\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for target in y_test_trans:\n",
    "    total += 1\n",
    "    pred_idx = random.randrange(0, 11)\n",
    "    #print(pred_idx)\n",
    "    if target[pred_idx]==1:\n",
    "        correct += 1\n",
    "\n",
    "print(\"{} out of {} correct, resulting in an accuracy of {}\".format(correct, total, (correct/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keywords2",
   "language": "python",
   "name": "keywords2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
